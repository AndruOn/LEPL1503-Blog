---
layout: post
title: Une bonne connaissance du fonctionnement des processeurs reste nécessaire
author: Olivier Bonaventure
---

En une petite cinquantaine d'années, les microprocesseurs ont révolutionné l'informatique. Depuis les premières processeurs qui contenaient quelques milliers de transitors aux microprocesseurs actuels qui en regroupent plusieurs milliards, de nombreuses évolutions technologiques se sont succédées. Il est impossible de résumer ces évolutions en quelques lignes, mais je ne peux que vous recommander de consulter deux blog posts.

Le premier, posté en 2016 sur [http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/](http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/) résume en un graphique reproduit ci-dessous le coût des principales opérations que l'on peut exécuter sur un CPU. Ces ordres de grandeurs doivent être connu par tout informaticien qui cherchent à optimiser son code de façon à le rendre plus efficace.

![http://ithare.com/wp-content/uploads/part101_infographics_v08.png](http://ithare.com/wp-content/uploads/part101_infographics_v08.png)

Au-delà de la figure qui est un excellent résumé à afficher sur les postes des salles informatiques, la discussion de ces différents chiffres et les explications reprises sur le blog sont très intéressantes.

Le [second blog post](https://www.sigarch.org/whats-the-future-of-technology-scaling/) a été écrit par [David Brooks](http://www.eecs.harvard.edu/~dbrooks/) et publié sur [Computer Architecture Today](https://www.sigarch.org/blog/), le blog de [SIGARCH](https://www.sigarch.org). Ce post analyse en détails les facteurs qui pourraient conduire à un arrêt de la [loi de Moore](https://en.wikipedia.org/wiki/Moore%27s_law) et les directions dans lesquelles les futurs processeurs pourraient évoluer. Les prédictions du futur restent difficiles, mais David Brooks s'appuie sur des données chiffrées et pas mal d'arguments pertinents. Il est probablement qu'un jour pour exploiter correctement les futurs processeurs il sera nécessaire de dépasser le modèle de Von Neumann et l'abstraction du fonctionnement purement séquentiel des processeurs. Cela nécessitera de nouveaux langages de programmation et le développement de nouvelles techniques de programmation pour mieux tirer parti de ces processeurs.
